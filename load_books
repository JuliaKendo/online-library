import os
import re
import requests
from bs4 import BeautifulSoup
from pathvalidate import sanitize_filename
from urllib.parse import urljoin


def get_soup(url, book_id):
    book_url = f'{url}/b{book_id}/'
    response = requests.get(book_url)
    response.raise_for_status()
    assert book_url == response.url, 'Отсутствует книга на сайте'
    return BeautifulSoup(response.text, 'lxml')


def get_book_image(url, soup):
    image_link = soup.find('div', class_='bookimage').find('img')['src']
    if image_link:
        return urljoin(url, image_link)


def get_book_atributes(soup):
    book_atributes = {
        'name': '',
        'author': '',
        'genres': ''
    }
    title_tag = soup.find('div', id='content').find('h1')
    if title_tag:
        book_name, book_author = re.findall(r'^(.*?)\s::(.*)', title_tag.text)[0]
        book_atributes['name'] = book_name.strip()
        book_atributes['author'] = book_author.strip()

    genre_tag = soup.find('div', id='content').find('span', class_='d_book').find_all('a')
    book_atributes['genres'] = [genre.text for genre in genre_tag if genre_tag]

    return book_atributes


def get_filename(book_atributes, book_id):
    filename = '%s.%s.txt' % (book_id, book_atributes['name'])
    return sanitize_filename(filename)


def download_image(url, filename, folder='images/'):
    response = requests.get(url)
    response.raise_for_status()

    os.makedirs(folder, exist_ok=True)
    filename = os.path.join(folder, filename)
    with open(filename, 'wb') as file:
        file.write(response.content)

    return filename


def download_txt(url, filename, book_id, folder='books/'):
    response = requests.get(f'{url}/txt.php', params={'id': book_id})
    response.raise_for_status()

    os.makedirs(folder, exist_ok=True)
    filename = os.path.join(folder, filename)
    with open(filename, 'w') as file:
        file.write(response.text)

    return filename


def download_comments(soup):
    comments_tag = soup.find_all('div', class_='texts')
    if comments_tag:
        return [comment.find('span').text for comment in comments_tag]


def main():
    url = 'http://tululu.org'
    for book_id in range(1, 11):
        try:
            soup = get_soup(url, book_id)
            book_atributes = get_book_atributes(soup)

            filename = get_filename(book_atributes, book_id)
            filepath = download_txt(url, filename, book_id)

            url_image = get_book_image(url, soup)
            filename = url_image.split('/')[-1]
            book_image = download_image(url_image, filename)

            comments = download_comments(soup)

            print(filepath)
            print(book_image)
            if comments:
                print(comments)
            print(book_atributes['genres'])

        except AssertionError:
            continue

        except AttributeError:
            continue


if __name__ == "__main__":
    main()
